created: 20210901041518681
modified: 20210902042712049
tags: [[Prompted Introspection]]
title: 2021.09.01 - Prompted Introspection: Cypher's Wirehead

!! If you could, would you wirehead (i.e. hook yourself up to a hypothetical machine that makes you totally and eternally happy and satisfied)?

Oh, I roughly call that [[Cypher's Choice]]. I think there are conceptual limits to maximizing hedons and satisfaction, but I'll agree that the highest [[dok]] of eudaimonia will usually be divorced from the [[good]] of all [[others]] to some non-trivial [[dok]] (only some are necessary for one's individual happiness, especially with effective self-deception),<<ref "f">> being moral, and living in reality.<<ref "a">> But, perhaps if we all lived in particular versions of what [[Cypher's Choice]] could offer us (closer to AR) or a more utopic material world constructed through said automation (I admit this is possible), then perhaps our eudaimonia could be justified and not come at these great moral costs.

I don't run into that term "Wirehead" often (not usually what I would mean by it, as I think of "gearhead," etc). Note that your definition does not match the sci-fi usage so cleanly. One could imagine machines that didn't simply pump you full of chemicals or even simulate worlds for your [[phenomenology]], but, in fact, altered the world itself quite thoroughly.<<ref "g">> On that possibility, I would likely agree to some narrow types of wireheading. I don't think that's what you intended though. 

The Nozickian Experience Machine question picks out a serious moral intuition. There is a priority to reality and a set of duties that arise out of that fact. It's not like I'm not tempted to live in a mere simulation rather than augmenting reality, insofar as that is even up to me. I ought not, and I [[hope]] I would not. I am not convinced that my life cannot make a difference in this world, but if that were provably the case, then there may be types of simulations and artificial hedon production tools that I could further justify.


---
<<footnotes "f" "Finite resources give way to zero-sum games at some level.">>

<<footnotes "a" "As close as we get to things-in-themselves, in [[faith]].">>

<<footnotes "g" "It'd be interesting to be hooked up to the thing saving the world, watching the fabled transhumanist's permaculture utopia unfold before your very eyes.">>